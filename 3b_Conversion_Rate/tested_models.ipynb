{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.8/site-packages (5.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from plotly) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# setting Jedha color palette as default\n",
    "pio.templates[\"jedha\"] = go.layout.Template(\n",
    "    layout_colorway=[\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\", \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"]\n",
    ")\n",
    "pio.templates.default = \"jedha\"\n",
    "pio.renderers.default = \"svg\" # to be replaced by \"iframe\" if working on JULIE\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set with labels (our train+test) : (284580, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression with 2 features\n",
    "###### \"total_pages_visited\" & \"new_user\"\n",
    "\n",
    "###### f1-score on train set :  0.6938517686692869\n",
    "###### f1-score on test set :  0.7060240963855423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_pages_visited  new_user\n",
      "0                    2         1\n",
      "1                    3         1\n",
      "2                   14         0\n",
      "3                    3         1\n",
      "4                    3         1\n",
      "\n",
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "Train model...\n",
      "...Done.\n",
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 0.63778957]\n",
      " [ 0.03879562]\n",
      " [-0.26070136]\n",
      " [-0.26070136]\n",
      " [ 0.63778957]]\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "f1-score on train set :  0.6938517686692869\n",
      "f1-score on test set :  0.7060240963855423\n"
     ]
    }
   ],
   "source": [
    "features_list1 = ['total_pages_visited', 'new_user']\n",
    "target_variable = 'converted'\n",
    "\n",
    "X1 = data.loc[:, features_list1]\n",
    "Y1 = data.loc[:, target_variable]\n",
    "\n",
    "print(X1.head())\n",
    "print()\n",
    "\n",
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y1, test_size=0.1, random_state=0)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "num_features1 = [\"total_pages_visited\"]\n",
    "num_transformer1 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers =[\n",
    "    (\"num_transformer\", num_transformer1, num_features1)\n",
    "])\n",
    "\n",
    "X_train1 = preprocessor.fit_transform(X_train1)\n",
    "X_train1[:5]\n",
    "\n",
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier = LogisticRegression() # \n",
    "classifier.fit(X_train1, Y_train1)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred1 = classifier.predict(X_train1)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred1)\n",
    "print()\n",
    "\n",
    "# Use X_test, and the same preprocessings as in training pipeline, \n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test1 = preprocessor.transform(X_test1)\n",
    "print(\"...Done\")\n",
    "print(X_test1[0:5,:])\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred1 = classifier.predict(X_test1)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred1)\n",
    "print()\n",
    "\n",
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train1, Y_train_pred1))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test1, Y_test_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression with 2 features\n",
    "###### \"total_pages_visited\" & \"country\"\n",
    "\n",
    "###### f1-score on train set :  0.7180902442389955\n",
    "###### f1-score on test set :  0.7223880597014924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_pages_visited  country\n",
      "0                    2    China\n",
      "1                    3       UK\n",
      "2                   14  Germany\n",
      "3                    3       US\n",
      "4                    3       US\n",
      "\n",
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "Train model...\n",
      "...Done.\n",
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 0.63778957  0.          0.          1.        ]\n",
      " [ 0.03879562  0.          0.          1.        ]\n",
      " [-0.26070136  0.          0.          1.        ]\n",
      " [-0.26070136  1.          0.          0.        ]\n",
      " [ 0.63778957  0.          0.          1.        ]]\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "f1-score on train set :  0.7180902442389955\n",
      "f1-score on test set :  0.7223880597014924\n"
     ]
    }
   ],
   "source": [
    "features_list2 = ['total_pages_visited', 'country']\n",
    "target_variable = 'converted'\n",
    "\n",
    "X2 = data.loc[:, features_list2]\n",
    "Y2 = data.loc[:, target_variable]\n",
    "\n",
    "print(X2.head())\n",
    "print()\n",
    "\n",
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, test_size=0.1, random_state=0)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "num_features2 = [\"total_pages_visited\"]\n",
    "num_transformer2 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_features2 = [\"country\"]\n",
    "cat_transformer2 = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "preprocessor2 = ColumnTransformer(transformers =[\n",
    "    (\"num_transformer\", num_transformer2, num_features2),\n",
    "    (\"cat_transformer\", cat_transformer2, cat_features2)\n",
    "])\n",
    "\n",
    "X_train2 = preprocessor2.fit_transform(X_train2)\n",
    "X_train2[0:5,:]\n",
    "\n",
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier2 = LogisticRegression() # \n",
    "classifier2.fit(X_train2, Y_train2)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred2 = classifier2.predict(X_train2)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred2)\n",
    "print()\n",
    "\n",
    "# Use X_test, and the same preprocessings as in training pipeline, \n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test2 = preprocessor2.transform(X_test2)\n",
    "print(\"...Done\")\n",
    "print(X_test2[0:5,:])\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred2 = classifier2.predict(X_test2)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred2)\n",
    "print()\n",
    "\n",
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train2, Y_train_pred2))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test2, Y_test_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression with 2 features\n",
    "###### \"total_pages_visited\" & \"age\"\n",
    "\n",
    "###### f1-score on train set : 0.7049306088290676 \n",
    "###### f1-score on test set : 0.7150635208711434 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['total_pages_visited', 'age'], dtype='object')\n",
      "\n",
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "Train model...\n",
      "...Done.\n",
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 0.63778957 -1.27809213]\n",
      " [ 0.03879562  0.05264881]\n",
      " [-0.26070136 -0.31028053]\n",
      " [-0.26070136 -0.67320988]\n",
      " [ 0.63778957  1.62534265]]\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "f1-score on train set :  0.7049306088290676\n",
      "f1-score on test set :  0.7150635208711434\n"
     ]
    }
   ],
   "source": [
    "features_list3 = ['total_pages_visited', 'age']\n",
    "target_variable = 'converted'\n",
    "\n",
    "\n",
    "X3 = data.loc[:, features_list3]\n",
    "Y3 = data.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X3.columns)\n",
    "print()\n",
    "\n",
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X3, Y3, test_size=0.1, random_state=0)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "\n",
    "num_features3 = [\"total_pages_visited\", \"age\"]\n",
    "num_transformer3 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "preprocessor3 = ColumnTransformer(transformers =[\n",
    "    (\"num_transformer\", num_transformer3, num_features3)\n",
    "])\n",
    "\n",
    "X_train3 = preprocessor3.fit_transform(X_train3)\n",
    "X_train3[:5]\n",
    "\n",
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier3 = LogisticRegression() # \n",
    "classifier3.fit(X_train3, Y_train3)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred3 = classifier3.predict(X_train3)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred3)\n",
    "print()\n",
    "\n",
    "# Use X_test, and the same preprocessings as in training pipeline, \n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test3 = preprocessor3.transform(X_test3)\n",
    "print(\"...Done\")\n",
    "print(X_test3[0:5,:])\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred3 = classifier3.predict(X_test3)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred3)\n",
    "print()\n",
    "\n",
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train3, Y_train_pred3))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test3, Y_test_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logistic Regression with 2 features\n",
    "###### \"total_pages_visited\" & \"source\"\n",
    "\n",
    "###### f1-score on train set : 0.6938517686692869\n",
    "###### f1-score on test set : 0.7060240963855423 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['total_pages_visited', 'source'], dtype='object')\n",
      "\n",
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "Train model...\n",
      "...Done.\n",
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 0.63778957  0.          0.        ]\n",
      " [ 0.03879562  0.          1.        ]\n",
      " [-0.26070136  0.          1.        ]\n",
      " [-0.26070136  0.          0.        ]\n",
      " [ 0.63778957  0.          0.        ]]\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "f1-score on train set :  0.6938517686692869\n",
      "f1-score on test set :  0.7060240963855423\n"
     ]
    }
   ],
   "source": [
    "features_list4 = ['total_pages_visited', 'source']\n",
    "target_variable = 'converted'\n",
    "\n",
    "\n",
    "X4 = data.loc[:, features_list4]\n",
    "Y4 = data.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X4.columns)\n",
    "print()\n",
    "\n",
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train4, X_test4, Y_train4, Y_test4 = train_test_split(X4, Y4, test_size=0.1, random_state=0)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "\n",
    "num_features4 = [\"total_pages_visited\"]\n",
    "num_transformer4 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_features4 = [\"source\"]\n",
    "cat_transformer4 = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "\n",
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "preprocessor4 = ColumnTransformer(transformers =[\n",
    "    (\"num_transformer\", num_transformer4, num_features4),\n",
    "    (\"cat_transformer\", cat_transformer4, cat_features4)\n",
    "])\n",
    "\n",
    "X_train4 = preprocessor4.fit_transform(X_train4)\n",
    "X_train4[:5]\n",
    "\n",
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier4 = LogisticRegression() # \n",
    "classifier4.fit(X_train4, Y_train4)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred4 = classifier4.predict(X_train4)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred4)\n",
    "print()\n",
    "\n",
    "# Use X_test, and the same preprocessings as in training pipeline, \n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test4 = preprocessor4.transform(X_test4)\n",
    "print(\"...Done\")\n",
    "print(X_test4[0:5,:])\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred4 = classifier4.predict(X_test4)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred4)\n",
    "print()\n",
    "\n",
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train4, Y_train_pred4))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test4, Y_test_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Decision Tree on all features\n",
    "\n",
    "###### f1-score on train set : 0.7983466594389484\n",
    "###### f1-score on test set : 0.7222562844880442  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "\n",
      "Y : \n",
      "   converted\n",
      "0          0\n",
      "1          0\n",
      "2          1\n",
      "3          0\n",
      "4          0\n",
      "\n",
      "X :\n",
      "   country  age  new_user  source  total_pages_visited\n",
      "0    China   22         1  Direct                    2\n",
      "1       UK   21         1     Ads                    3\n",
      "2  Germany   20         0     Seo                   14\n",
      "3       US   23         1     Seo                    3\n",
      "4       US   28         1  Direct                    3\n",
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "Train model...\n",
      "...Done.\n",
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[-0.79365434  2.73051047  0.          0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [ 0.53653379  0.03808136  0.          0.          1.          0.\n",
      "   1.          0.        ]\n",
      " [-0.18902337 -0.26107743  0.          0.          1.          0.\n",
      "   1.          0.        ]\n",
      " [ 0.05282902  0.93555773  0.          0.          0.          1.\n",
      "   0.          1.        ]\n",
      " [-0.30994956 -0.85939501  0.          0.          1.          1.\n",
      "   0.          1.        ]]\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "f1-score on train set :  0.7983466594389484\n",
      "f1-score on test set :  0.7222562844880442\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "#print(\"Separating labels from features...\")\n",
    "#features_list = [\"total_pages_visited\"]\n",
    "#target_variable = \"converted\"\n",
    "\n",
    "X5 = data.iloc[:,:-1]\n",
    "Y5 = data.iloc[:,-1:]\n",
    "\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "print('Y : ')\n",
    "print(Y5.head())\n",
    "print()\n",
    "print('X :')\n",
    "print(X5.head())\n",
    "\n",
    "\n",
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train5, X_test5, Y_train5, Y_test5 = train_test_split(X5, Y5, test_size=0.1, random_state=0, stratify=Y5)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "\n",
    "num_features5 = [\"age\", \"total_pages_visited\"]\n",
    "num_transformer5 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_features5 = [\"country\", \"new_user\", \"source\"]\n",
    "cat_transformer5 = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "preprocessor5 = ColumnTransformer(transformers =[\n",
    "    (\"num_transformer\", num_transformer5, num_features5),\n",
    "    (\"cat_transformer\", cat_transformer5, cat_features5)\n",
    "])\n",
    "\n",
    "X_train5 = preprocessor5.fit_transform(X_train5)\n",
    "X_train5[:5]\n",
    "\n",
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier5 = DecisionTreeClassifier() # \n",
    "classifier5.fit(X_train5, Y_train5)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred5 = classifier5.predict(X_train5)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred5)\n",
    "print()\n",
    "\n",
    "# Use X_test, and the same preprocessings as in training pipeline, \n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test5 = preprocessor5.transform(X_test5)\n",
    "print(\"...Done\")\n",
    "print(X_test5[0:5,:])\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred5 = classifier5.predict(X_test5)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred5)\n",
    "print()\n",
    "\n",
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train5, Y_train_pred5))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test5, Y_test_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
